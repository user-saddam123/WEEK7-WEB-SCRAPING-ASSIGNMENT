{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae073db-d917-4007-b0b4-1bb240249c13",
   "metadata": {},
   "source": [
    "Web Scrapping/Assignment/Solution/by-saddam ansari/for /pwskills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65235f76-6998-4e91-9802-19cfe0d2ab9b",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d083834d-17df-4e03-88c5-d8fa06ef5723",
   "metadata": {},
   "source": [
    "Web scraping is the process of automatically extracting data from websites. It involves using software or scripts to retrieve information from web pages, parse the HTML or other structured formats, and then save the extracted data in a structured format like a spreadsheet or database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244dca7e-433d-47ca-a9a7-9017fe1c4c4b",
   "metadata": {},
   "source": [
    "Web scraping is used for various purposes, includin\n",
    "1. Data Collection\n",
    "2. Competitive Analysis\n",
    "3. Market Research\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a0b1a2-a030-4cde-a52d-a5f0a8c151d3",
   "metadata": {},
   "source": [
    "Three areas where web scraping is commonly used to obtain data are:\n",
    "1. E-Commerce: Web scraping is frequently used in the e-commerce sector to gather product information, prices, reviews, and availability from various online retailers.\n",
    "2. Real Estate: Real estate professionals and investors use web scraping to collect property listings, prices, and other relevant information from real estate websites.\n",
    "3. Financial Data: Web scraping is also widely used in the financial sector to collect stock market data, financial news, and other relevant information from financial news websites, stock exchanges, and other financial sources. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca0bc6-ff7a-4973-94d8-d941372ce602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a59ea333-d182-4dcc-9c24-c17c1928f6cb",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51253104-1e7d-4357-b8a4-cdf1dff9fd8e",
   "metadata": {},
   "source": [
    "Here are some common methods used for web scraping:\n",
    "\n",
    "1. Manual Copy-Pasting: This is the simplest form of web scraping, where a user manually selects and copies the desired data from a web page and then pastes it into a spreadsheet or text document. \n",
    "\n",
    "2. HTML Parsing Libraries: These libraries, such as BeautifulSoup for Python, allow you to parse HTML and XML documents and extract specific elements based on tags, attributes, and classes.\n",
    "\n",
    "3. Web Scraping Frameworks: There are frameworks like Scrapy (Python) that offer a higher level of abstraction for building web scrapers. They handle tasks like making requests, handling responses, and parsing the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8964b3e-f155-4062-bd74-5d3b3065c2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "170720d7-2c8c-4a42-b537-7772e7aca417",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5283b-9f53-464a-abb2-44c7d30dd6c3",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library that is widely used for web scraping purposes. It provides tools for parsing HTML and XML documents and extracting data from them in a structured and convenient way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fec9b9-d647-42e7-8b5d-8c85f20198f4",
   "metadata": {},
   "source": [
    "Here's why Beautiful Soup is used:\n",
    "\n",
    "1. HTML Parsing and Navigation: Beautiful Soup helps you parse HTML and XML documents, creating a parse tree that allows you to navigate and search through the document's elements, tags, attributes, and text content.\n",
    "\n",
    "2. Structured Output: Beautiful Soup converts the parsed HTML into a navigable data structure that makes it straightforward to access and manipulate the content\n",
    "\n",
    "3. Easy Data Extraction: It provides simple methods for extracting specific data, such as finding elements by tag name, class, ID, or attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bce2ff-dbdf-4ead-bb39-3f35b2db2694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b62a2345-28a4-4f4e-b907-9bbfd2b6b962",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d8da1-5577-4c9f-be0c-ede8a1931818",
   "metadata": {},
   "source": [
    "Flask is a lightweight web framework for Python that is commonly used for building web applications. While Flask itself is not directly related to web scraping, it can be used in a web scraping project for several reasons:\n",
    "\n",
    "1. Web Interface: Flask allows you to create a web-based user interface for your web scraping project.\n",
    "\n",
    "2. Data Presentation: After scraping data from websites, you might want to present the extracted data to users in a readable and organized format.\n",
    "\n",
    "3. Deployment: Flask applications are relatively easy to deploy, making it convenient to host your web scraping project on a server or cloud platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a100e63-c324-4e46-a7cc-7c8c49a30035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb935a8-6810-42a2-9e4a-fc15f746ae31",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dec89-73a0-4deb-9ddd-2b7aa259465d",
   "metadata": {},
   "source": [
    "In a web scraping project hosted on AWS (Amazon Web Services), several services can be utilized to build and deploy the project. Here are some AWS services-\n",
    "\n",
    "1. Amazon EC2 (Elastic Compute Cloud)\n",
    "2. Amazon S3 (Simple Storage Service)\n",
    "3. Amazon RDS (Relational Database Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4188a-e882-4a13-976d-535a1a948928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4738b20a-985d-476f-8b8c-7aff83e1b695",
   "metadata": {},
   "source": [
    ". Name- Saddam ansari\n",
    ". Place_sahasa\n",
    ".date-10/08/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17413f6b-d88c-4169-8a7f-c5e703c690fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
